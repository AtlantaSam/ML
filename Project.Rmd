## Project

### Libraries

```{r}
library(caret)
library(ggplot2)
library(knitr)
library(randomForest)
library(doParallel)
```

### Load Data
```{r}
#download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv', 'pml-training.csv',method='curl')
#download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv','pml-test.csv',method='curl')
```

### Tidy Data
Convert all blank(‘“”’), ‘#DIV/0’ and ‘NA’ values are converted to ‘NA’.
```{r}
trainingSrc   <- read.csv('pml-training.csv', na.strings=c("NA","#DIV/0!", ""))
testSrc       <- read.csv('pml-test.csv' , na.strings=c("NA", "#DIV/0!", ""))
```

We decided to leave columns having no more than 60% of NA values:
```{r}
goodVars    <- which((colSums(!is.na(trainingSrc)) >= 0.6*nrow(trainingSrc)))
trainingSrc <- trainingSrc[,goodVars]
testSrc     <- testSrc[,goodVars]
```

Some minor fixes to test set are needed to perform well with random forests.
```{r}
# remove problem id
testSrc <- testSrc[-ncol(testSrc)]
# fix factor levels
testSrc$new_window <- factor(testSrc$new_window, levels=c("no","yes"))
```

Remove X and cvtd_timestamp colums from the dataset since they are not relevant
```{r}
trainingSrc <- trainingSrc[,-c(1,5)]
testSrc     <- testSrc[,-c(1,5)]
```

### Partition Data
```{r}
inTraining  <- createDataPartition(trainingSrc$classe, p = 0.6, list = FALSE)
training    <- trainingSrc[inTraining, ]
testing     <- trainingSrc[-inTraining, ]
```

### Fitting Random Forests
The outcome variable is class and other colums are in data dataframe.
```{r}
class <- training$classe
data  <- training[-ncol(training)]
```

We will use Parallel Random Forest algorithm to fit the model. Note that for random forests there is no need for cross-validation to get an unbiased estimate of the test set error. It is estimated internally during the fitting process.

```{r}
registerDoParallel()
rf <- train(data, class, method="parRF", 
    tuneGrid=data.frame(mtry=3), 
    trControl=trainControl(method="none"))
```

```{r}
rf
```

Let’s plot importance of the model variables:
```{r}
plot(varImp(rf))
```

### Confusion Matrix
Predict on testing set and generate the confusion matrix for the testing set
```{r}
testingPredictions <- predict(rf, newdata=testing)
confMatrix <- confusionMatrix(testingPredictions,testing$classe)
confMatrix
```

Let’s have a look at the accuracy
```{r}
confMatrix$overall[1]
```